{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWwlR8DaisTH"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "data = load_dataset(\"riddle_sense\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MBxaGr51ckH"
      },
      "source": [
        "**Task 1:**\n",
        "Create a new dataset where each possible answer appears only once."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ipwpPEP1QoQ"
      },
      "outputs": [],
      "source": [
        "listOfIndicesToSelect = list()\n",
        "listOfIndicesToRemove = list()\n",
        "allWordSet = set()\n",
        "for index,sample in enumerate(data[\"train\"]):\n",
        "  # print(\"The choices are: \",sample[\"choices\"][\"text\"])\n",
        "  shouldAddFlag = 1\n",
        "  for word in sample[\"choices\"][\"text\"]:\n",
        "    if word in allWordSet:\n",
        "      shouldAddFlag = 0\n",
        "      # print(f\"---Found Repeat!---word: {word}, set is: {allWordSet}\")\n",
        "      # print(f\"Current list of indices: {listOfIndicesToRemove}\")\n",
        "      break\n",
        "    else:\n",
        "      allWordSet.add(word)\n",
        "      # print(f\"---New Word!_--, set is {allWordSet}\")\n",
        "  if shouldAddFlag:\n",
        "    listOfIndicesToSelect.append(index)\n",
        "  else:\n",
        "    listOfIndicesToRemove.append(index)\n",
        "\n",
        "# print(f\"number of samples to add: {len(listOfIndicesToSelect)}\")\n",
        "# print(f\"number of samples to remove: {len(listOfIndicesToRemove)}\")\n",
        "\n",
        "newDataset = data[\"train\"].select(listOfIndicesToSelect)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egsz17vW880b",
        "outputId": "12bb62a4-0b25-4bf5-d3ca-b5eed72a606c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['answerKey', 'question', 'choices'],\n",
              "    num_rows: 657\n",
              "})"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "newDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoHqOYwG7uYf"
      },
      "outputs": [],
      "source": [
        "listOfIndicesToSelect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fsutRjoZ8Fqx"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import torch\n",
        "# load correctness and true_label_prob\n",
        "with open('/content/stats.pkl', 'rb') as f:\n",
        "    data_loaded = pickle.load(f)\n",
        "\n",
        "# Access\n",
        "correctness = data_loaded['correctness']\n",
        "true_label_probs = data_loaded['true_label_probs']\n",
        "confidence = torch.mean(true_label_probs, dim=1) # mean prob of TRUE labels across all instances in eval_data\n",
        "variability = torch.std(true_label_probs, dim=1, correction=0) # std prob of TRUE labels across all instances in in eval_data\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(confidence[:5])\n",
        "print(variability[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JYv7KNl9wzw",
        "outputId": "7ab95bd4-c42e-42c6-9df2-59358a3850ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.7555, 0.7266, 0.7194, 0.7498, 0.7353])\n",
            "tensor([0.2531, 0.3038, 0.3392, 0.2963, 0.3065])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "newCorrectness =torch.take(correctness, torch.tensor(listOfIndicesToSelect))\n",
        "newConfidence =torch.take(confidence, torch.tensor(listOfIndicesToSelect))\n",
        "newVariability =torch.take(variability, torch.tensor(listOfIndicesToSelect))\n"
      ],
      "metadata": {
        "id": "BZWcV4w-8kQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "# Compute bins of correctness\n",
        "bins = np.digitize(newCorrectness, bins=[0.0000001, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
        "\n",
        "# Create a dictionary to map bin numbers to bin labels\n",
        "bin_labels = {0:'0', 1: '(0.0-0.1)', 2: '[0.1-0.2)', 3: '[0.2-0.3)', 4: '[0.3-0.4)', 5: '[0.4-0.5)', 6: '[0.5-0.6)',7: '[0.6-0.7)',8: '[0.7-0.8)',9:'[0.8-0.9)',10: '[0.9-1)', 11:'1'}\n",
        "\n",
        "# Apply the mapping to bins to get bin labels\n",
        "bins_str = np.vectorize(bin_labels.get)(bins)\n",
        "\n",
        "colors = px.colors.sample_colorscale(\"Jet\", [n/(11) for n in range(12)])\n",
        "\n",
        "fig = px.scatter(\n",
        "    x=newVariability.numpy().squeeze(),\n",
        "    y=newConfidence.numpy().squeeze(),\n",
        "    color=bins_str.squeeze(),\n",
        "    symbol=bins_str.squeeze(),\n",
        "    color_discrete_sequence=colors,\n",
        "    labels={\n",
        "        \"color\": \"newCorrectness\",\n",
        "        \"symbol\": \"newCorrectness\",\n",
        "        \"y\": \"Confidence\",\n",
        "        \"x\": \"variability\"\n",
        "    },\n",
        "    category_orders = {\"color\": list(bin_labels.values())[::-1]}\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "lCR3In8N8aez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_points(confidence_threshold = 0.2, variability_threshold = 0.2):\n",
        "    hard_to_learn = []\n",
        "    easy_to_learn=[]\n",
        "    ambiguous=[]\n",
        "    for i, datapoint in enumerate(riddleSense_train_map_pre):\n",
        "      conf = confidence[i]\n",
        "      var = variability[i]\n",
        "      # Hard to learn\n",
        "      if conf < confidence_threshold and var < variability_threshold:\n",
        "        hard_to_learn.append(i)\n",
        "\n",
        "      # Easy to learn\n",
        "      elif conf>= confidence_threshold and var < variability_threshold:\n",
        "        easy_to_learn.append(i)\n",
        "      # Ambigious\n",
        "      else:\n",
        "        ambiguous.append(i)\n",
        "\n",
        "    data_dict = {\"easy_to_learn\": easy_to_learn,\n",
        "                  \"hard_to_learn\": hard_to_learn,\n",
        "                  \"ambiguous\": ambiguous}\n",
        "    return data_dict\n"
      ],
      "metadata": {
        "id": "CY9gS_ZB-HuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZSIsQjfHSw4"
      },
      "outputs": [],
      "source": [
        "# Test that each possible answer appears only once. Result should be nothing printed\n",
        "\n",
        "mapDict = {\"A\": 0, \"B\": 1, \"C\":2, \"D\":3, \"E\":4}\n",
        "result = []\n",
        "for sample in newDataset:\n",
        "  result.append(sample[\"choices\"][\"text\"][mapDict[sample[\"answerKey\"]]])\n",
        "\n",
        "result = np.array(result)\n",
        "a = np.unique(result, return_counts=True)\n",
        "\n",
        "for index, word in enumerate(a[0]):\n",
        "  if a[1][index] != 1:\n",
        "    print(f\"word: {word}, times: {a[1][index]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnCtQwyL2hyr"
      },
      "outputs": [],
      "source": [
        "# Test that each possible answer appears only once. Result should be all 1's\n",
        "\n",
        "check = list()\n",
        "for sample in newDataset:\n",
        "  for word in sample[\"choices\"]:\n",
        "    check.append(word)\n",
        "\n",
        "check = np.array(check)\n",
        "a = np.unique(result, return_counts=True)\n",
        "print(a[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u42xpaOz3E4K"
      },
      "source": [
        "Task 2: Create the following statistic about each possible answer:\n",
        "Number of times that the word/phrase appeard in a correct answer out of the number of times the word/phrase appeared as a possible answer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YnT2j6fHwDO"
      },
      "outputs": [],
      "source": [
        "mapDict = {\"A\": 0, \"B\": 1, \"C\":2, \"D\":3, \"E\":4}\n",
        "result = []\n",
        "for sample in data[\"train\"]:\n",
        "  result.append(sample[\"choices\"][\"text\"][mapDict[sample[\"answerKey\"]]])\n",
        "\n",
        "result = np.array(result)\n",
        "a = np.unique(result, return_counts=True)\n",
        "\n",
        "# j = 0\n",
        "# for index, word in enumerate(a[0]):\n",
        "#   if a[1][index] != 1:\n",
        "#     print(f\"word: {word}, times: {a[1][index]}\")\n",
        "    # j+=1\n",
        "# print(j)\n",
        "\n",
        "probs = {}\n",
        "for index,word in enumerate(a[0]):\n",
        "  probs[word] = [a[1][index], 0]\n",
        "\n",
        "# j = 0\n",
        "for sample in data[\"train\"]:\n",
        "  for word in sample[\"choices\"][\"text\"]:\n",
        "    if word not in probs:\n",
        "      probs[word] = [0, 1]\n",
        "      # j += 1\n",
        "    else:\n",
        "      probs[word][1] += 1\n",
        "# print(j)\n",
        "\n",
        "always1 = dict()\n",
        "always0 = dict()\n",
        "others = dict()\n",
        "\n",
        "realProbsDict = {}\n",
        "for word in probs:\n",
        "  prob = probs[word][0]/probs[word][1]\n",
        "  realProbsDict[word] = prob\n",
        "  if prob == 1:\n",
        "    always1[word] = 1\n",
        "  elif prob == 0:\n",
        "    always0[word] = 0\n",
        "  else:\n",
        "    others[word] = prob\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HU8B7e4lBaJp",
        "outputId": "2d097613-10a8-49ca-ead6-3e4d30558324"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10772"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = len(always1) + len(always0) + len(others)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDI4a7JvBQRX",
        "outputId": "c5005364-32ff-4b8f-eb24-c857d8493804"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.2702376531748979"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(always1)/x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb-w4HutBV_H",
        "outputId": "afb145c0-f45c-46e7-cb0c-6eacb0c40263"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7078536947642035"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(always0)/x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nurATejjBXGw",
        "outputId": "7c926591-3890-4ddc-ee9b-1a29941fb231"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.021908652060898627"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(others)/x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTYGAek64LAC"
      },
      "source": [
        "Task 3: Create a dataset that doesn't include simillar words (such as hole and holes) in as answers to different riddles."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}